### Benchmark
benchmark: 
    benchmark: "perqa"
    benchmark_dir: "./data/benchmarks/perqa"
    result_dir: "./data/results/perqa/reqap_sft"

### QU
qu:
    qu_execution_cache_size: 100  #EFFICIENCY / MEMORY trade-off
    qu_mode_options: ["openai", "instruct_model", "seq2seq"] 
    qu_mode: "seq2seq"
    # qu - supervisor
    qu_supervisor_instr: "./prompts/instruction-qu_supervisor.txt"
    qu_supervisor_icl: "./prompts/icl-qu_supervisor.json"
    qu_icl_selection_strategy: "dynamic"
    qu_icl_num_examples: 8
    # qu - model
    causal: True
    qu_causal_instr: prompts/instruction-qu_causal.txt
    tokenizer_path: "./data/tokenizers/qu-tokenizer-llama-3.2-1B-Instruct"
    trained_model_path: "./data/models/perqa/qu-trained_model-llama-3.2-1B-Instruct"
    max_input_length: 800
    max_output_length: 512
    max_length: 1024
    qu_use_history: True
    qu_inference_batch_size: 20
    # qu - model - training
    qu_training:
        qu_correct_only: False
        qu_result_data:
            train: "./data/training_data/perqa/qu/train_data_results_openai.jsonl"
            dev: "./data/training_data/perqa/qu/dev_data_results_openai.jsonl"
        qu_data:
            train: "./data/training_data/perqa/qu/train_data.jsonl"
            dev: "./data/training_data/perqa/qu/dev_data.jsonl"
        qu_result_paths:
            train: "./data/results/perqa/reqap_openai/qu_train.jsonl"
            dev: "./data/results/perqa/reqap_openai/qu_dev.jsonl"
            test: "./data/results/perqa/reqap_openai/qu_test.jsonl"
    qu_result_paths:
        train: "./data/results/perqa/reqap_sft/qu_train.jsonl"
        dev: "./data/results/perqa/reqap_sft/qu_dev.jsonl"
        test: "./data/results/perqa/reqap_sft/qu_test.jsonl"
    # qu - model - generation
    sampling_params:
        n: 1  # number of branches in tree
        do_sample: False
        temperature: 0.0
        max_new_tokens: 200


### RETRIEVE
# splade
splade:
    splade_indices_dir: "./data/splade_indices/perqa"
    splade_model_type_or_path: "./data/models/splade-cocondenser-ensembledistil"
    splade_tokenizer_type: "./data/models/splade-cocondenser-ensembledistil"
    splade_max_length: 512
    splade_index_batch_size: 8
    splade_threshold: 0.1  # threshold for events derived by SPLADE in step 1 of RETRIEVE
    splade_verbalize_events: True  # enables linearization of events for retrieval (slight improvements)
crossencoder:
    # crossencoder - models
    model_patterns: 
        crossencoder_tokenizer_path: "./data/tokenizers/crossencoder-tokenizer-ms-marco-MiniLM-L-12-v2"
        crossencoder_trained_model_path: "./data/models/perqa/crossencoder-trained_model_patterns-ms-marco-MiniLM-L-12-v2"
        max_length: 50
        inference_batch_size: 128
    model_events: 
        crossencoder_tokenizer_path: "./data/tokenizers/crossencoder-tokenizer-ms-marco-MiniLM-L-12-v2"
        crossencoder_trained_model_path: "./data/models/perqa/crossencoder-trained_model_events-ms-marco-MiniLM-L-12-v2"
        max_length: 512
        inference_batch_size: 128  
    # retrieval pattern
    unified_negative_patterns: False  # whether candidate positive patterns can be used for pruning all (often noisy)
    retrieval_pattern:
        apply: True  # whether to utilize patterns to score events as sets
        min_events_matched_inference: 100  # absolute frequency threshold for patterns during inference

### EXTRACT
extract:
    # extract - model
    tokenizer_path: "./data/tokenizers/extract-tokenizer-bart-base"
    trained_model_path: "./data/models/perqa/extract-trained_model-bart-base"
    max_input_length: 512
    max_output_length: 512
    inference_batch_size: 128
    extract_sample_size_simple_lookup: 50  # number of EXTRACT samples to identify a simple mapping (e.g., date -> start_date)
    simple_lookup_threshold: 0.7 # threshold for exact matches for deriving simple mapping
    extract_add_persona: True  # adds salient information for persona (e.g., list of friends)
    merge_overlapping_events: True  # enables event de-duplication
    # extract - model - generation
    generation_params:
        num_beams: 1
        no_repeat_ngram_size: 3
        forced_bos_token_id: 0
