### Benchmark
benchmark: 
    benchmark: "perqa"
    benchmark_dir: "./data/benchmarks/perqa"
    result_dir: "./data/results/perqa/rag_llama"

### ICL
instruct_model:
    icl_model_path: "./data/models/llama/Llama-3.3-70B-Instruct"
    vllm_gpu_memory_utilization: 0.95
    vllm_max_model_len: 30000
    use_cache: False

answering:
    answering_mode_options: ["openai", "instruct_model", "seq2seq"] 
    answering_mode: "instruct_model"
    instruction: "./prompts/instruction-rag_answering.txt"
    prompt: "./prompts/prompt-rag_answering.txt"
    icl_examples: "./prompts/icl-rag_answering.json"
    max_num_events: 100

### RETRIEVE
# splade
splade:
    splade_indices_dir: "./data/splade_indices/perqa"
    splade_model_type_or_path: "./data/models/splade-cocondenser-ensembledistil"
    splade_tokenizer_type: "./data/models/splade-cocondenser-ensembledistil"
    splade_max_length: 512
    splade_index_batch_size: 8
    splade_threshold: 0.1
    splade_verbalize_events: True
crossencoder:
    # crossencoder - general
    model_events:
        crossencoder_tokenizer_path: "./data/tokenizers/perqa/crossencoder-tokenizer-ms-marco-MiniLM-L-2-v2"
        crossencoder_trained_model_path: "./data/models/perqa/crossencoder_rag-trained_model-ms-marco-MiniLM-L-2-v2"
        max_length: 512
        inference_batch_size: 128  # might be different from training time due to different device
    model_patterns: False
    retrieval_result_dir: "./data/results/perqa/rag_openai"
    
    # TRAINING via rag_openai.yml
    retrieval_pattern:
        apply: False
